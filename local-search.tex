\setlength{\tabcolsep}{6pt}
\vspace{-8mm}
\begin{tabu} to \linewidth {X[-2.5, c, m] | X[l,m]}
  \bf \footnotesize polynomial-time \newline searchable & A neigbourhood $f$, if there is
  a polynomial-time algorithm that, for every $x \in L_I$ and every $\alpha \in
  \M(x)$, find one of the best feasible solutions in $f_x(\alpha)$. \\ \hline
  \onecol{%
  $U$, an integer-valued optimization problem, is called
  {\bf cost-bounded} if, for every input instance $I \in L_I$, $Int(I) =
  (i_1, i_2, \ldots, i_n), i_j \in \N$ for $j = 1, \ldots, n$,
  $cost(\alpha) \leq \sum^n_{j=1}i_j$ for every $\alpha \in \M(I)$.} \\ \hline
  \onecol{%
  Let $U$ be an optimization problem from $\mathbf{NPO}$. We define the
  {\bf suboptimaly decision problem} to $U$ as the decision problem $(SUBPOPT_U,
  \Sigma_I \cup \Sigma_O)$ where $\mathbf{SUBOPT_U} = \{(x, \alpha) \in L_I
  \times \Sigma_O^* \mid \alpha \in \M(x)$ {\em and $\alpha$ is not
    optimal}$\}$.} \\ \hline
    $\mathbf{LSS(Neigh)}$ & Local search scheme in the neighbourhood $Neigh$,
  always picking the best neighbour. \\ \hline
  \onecol{\bf \centering Heuristics} \\ \hline
  \bf multistart \newline local search & $LSS(Neigh)$ with multiple random
  initial starting points. \\ \hline
  \bf threshold \newline local search & $LSS$ but allows to move to a weaker
  solution than the current when the deteriotation is not above a given
  threshold. \\ \hline
  \bf simulated \newline annealing & As $LSS$, but with a random pick and a
  probability of picking a worse solution, based on a temperature $T$. \\ \hline
  \onecol{%
    Let $U$ be an optimization problem. Let, for a given instance $x \in L_I$ of
    size $n$, every $\alpha \in \left\{0,1\right\}^n$ represent a feasible
    solution to $x$ (i.e. $\M(x) = \left\{0,1\right\}^n$). A {\bf schema for
      $\M(x)$} is any vector $s = (s_1, s_2, \ldots, s_n) \in
    \left\{0,1,*\right\}^n$. A {\bf set of feasible solutions of a schema}
      $\mathbf{s = (s_1, s_2, \ldots, s_n)}$ is {\em
    $\mathbf{Schema(s_1, s_2, \ldots, s_n)} = \{\gamma_1, \gamma_2, \ldots
    \gamma_n \in \M(x) \mid \gamma_i = s_i$ for all $i \in \{1, \ldots, n\}$ such
    that $s_i \in \{0, 1\}$ for all $j \in \{1, \ldots, n\}$ such that
    $s_i = *\}$} \vspace{1mm}\newline
    The {\bf length of a schema \textit{s}}, denoted $\mathbf{length(s)}$, is
    the distance between the first and the last non-$*$ position in $s$. The
    {\bf order of a schema \textit{s}}, denoted $\mathbf{order(s)}$, is the
    number of non-$*$ positions. The {\bf fitness of a schema $\mathbf{s = (s_1,
        s_2, \ldots, s_n)}$ in a population \textit{P}} is the average fitness
    of feasible solutions in $Schema(s)$, i.e. \newline
    $\displaystyle\mathbf{Fitness(s, P)} = \cfrac{1}{|Schema(s) \cap P|} \cdot
    \sum_{\gamma \in Schema(s) \cap P} cost(\gamma)$ \vspace{1mm}\newline
    The {\bf fitness ratio of a schema \textit{s} in a population \textit{P}}
    is \vspace{1mm}\newline
    \phantom{------------------}
    $\displaystyle\mathbf{Fit\text{-}ratio(s, P)} =
    \frac{Fitness(s,P)}{\frac{1}{|P|}\sum_{\beta\in P} cost \beta}$
    \vspace{1mm}\newline
    $\mathbf{Aver\text{-}Fit(P)} = \frac{1}{|P|}\sum_{\beta\in P}cost(\beta)$ is
    called the {\bf average fitness of the population \textit{P}}.} \\ \hline
\end{tabu}
